<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

<<<<<<< HEAD
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>im2latex</title>
    <!-- Angular Material style sheet -->
    <link rel="stylesheet" href="https://ajax.googleapis.com/ajax/libs/angular_material/1.1.0/angular-material.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">
    <link rel="stylesheet" href="css/app.css">
</head>
=======
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
>>>>>>> 6e51b7fc9801a708e9223d85f7112e3ecdce09a3

    <title>Im2latex by dhoman01</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>Im2latex</h1>
        <h2>A &quot;Show, Attend, and Tell&quot; Approach</h2>
        <a href="https://github.com/dhoman01/im2latex" class="button"><small>View project on</small> GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h3>
<a id="abstract" class="anchor" href="#abstract" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h3>

<hr>

<p>The aim of this project was to create an intelligent system that could take images of mathematical equations and output a correct LaTeX representation of that equation. To accomplish the goals of the project two sub-branches of machine learning must be combined. First a convolutional neural network (CNN), a popular tool in image recognition, must be used to extract the features of the image. Then a sequence to sequence model is used to encode the rows of the CNN’s output and decode the resulting LaTeX output. Sequence to sequence models are a popular tool used in natural language processing. Thus, the overall strategy is to translate the pixels of an image into the language of LaTex. Furthermore, this project aims to compare three methods in their ability to perform the task. These methods are a Long-Short Term Memory(LSTM) model, a “show and tell” model, and a “show, attend, and tell” model.</p>

<p>Thus, the overall strategy is to translate the pixels of an image into the language of LaTex. Furthermore, this project aims to compare three methods in their ability to perform the task. These methods are a Long-Short Term Memory(LSTM) model, a “show and tell” model, and a “show, attend, and tell” model.</p>
        </section>

        <aside id="sidebar">
          <a href="https://github.com/dhoman01/im2latex/zipball/master" class="button">
            <small>Download</small>
            .zip file
          </a>
          <a href="https://github.com/dhoman01/im2latex/tarball/master" class="button">
            <small>Download</small>
            .tar.gz file
          </a>

          <p class="repo-owner"><a href="https://github.com/dhoman01/im2latex"></a> is maintained by <a href="https://github.com/dhoman01">dhoman01</a>.</p>

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the Architect theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>

  
  </body>
</html>
